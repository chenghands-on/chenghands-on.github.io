---
# Display name
title: è°¢æ‰¿ç¿°

# Name pronunciation (optional)
name_pronunciation: Chenghan Xie

# Full name (for SEO)
first_name: Chenghan
last_name: Xie

# Status emoji
status:
  icon: ðŸŽ“

# Is this the primary user of the site?
superuser: true

# Highlight the author in author lists? (true/false)
highlight_name: true

# Role/position/tagline
role: Ph.D. Student in Operations Research

# Organizations/Affiliations to display in Biography blox
organizations:
  - name: Stanford University
    url: https://www.stanford.edu/

# Social network links
profiles:
  - icon: at-symbol
    url: 'mailto:xxcchan@stanford.edu'
    label: E-mail Me
  - icon: brands/github
    url: https://github.com/chenghands-on
  - icon: brands/linkedin
    url: https://www.linkedin.com/in/chenghan-xie-6347992b6/
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?hl=en&user=-npEdYsAAAAJ&view_op=list_works&sortby=pubdate
  # - icon: brands/weixin
  #   url: # Your wechat link if needed

interests:
  - Efficient Employment of Generative AI
  - Reasoning & Multimodal Alignment
  - Stochastic Analysis & Diffusion Models

education:
  - area: Ph.D. in Operations Research, 2024 - 2029 (expected)
    institution: Stanford University
    summary: |
      Advisors: Jose Blanchet, Renyuan Xu
  - area: B.Sc. in Mathematics, 2020 - 2024
    institution: Fudan University
    summary: |
      GPA: 3.85/4.0 (Major GPA: 3.92/4.0)
      Ranking: 2/152

bio: Ph.D. Student at Stanford University

work:
  - position: Multimodal Interaction & World Model Intern
    company_name: ByteDance Seed
    date_start: 2025-06-01
    date_end: 2025-09-30
    summary: |
      - Accelerated diffusion model training by leveraging advances in representation learning.
      - Incorporated timestep scaling as a temperature factor during contrastive learning steps.
      - Improved FID from 15 to 13 by optimizing training signals and regularizers.
  - position: Algorithm Intern
    company_name: Shanghai Artificial Intelligence Laboratory
    date_start: 2024-02-01
    date_end: 2024-08-31
    summary: |
      - Built optics-domain benchmarks and integrated large models (GPT-4o, LLaMA-3).
      - Evaluated mainstream LLMs on domain-specific tasks focusing on reasoning capabilities.
      - Fine-tuned models like LLaMA 3 using QLORA and PEFT for scientific Q&A.

# Skills (Optional - kept structured but commented out based on your preference)
# skills:
#   - name: Technical Skills
#     items:
#       - name: Python (PyTorch, VLLM, Pandas)
#         percent: 100
#         icon: code-bracket
#       - name: Diffusion Models
#         percent: 90
#         icon: chart-bar
#       - name: LLM Training
#         percent: 90
#         icon: cpu-chip

---

## About Me

Welcome to my personal website! I am a first-year Ph.D. student in the **Operations Research** group at **Stanford University**, advised by Professors [Jose Blanchet]([https://www.stanford.edu/~joseblan/](https://joseblanchet.com/)) and [Renyuan Xu]([https://renyuanxu.github.io/](https://renyuanxu.github.io/)).

My research interests lie in the **Efficient Employment of Generative AI**, **Reasoning**, and **Multimodal Alignment**. I am particularly interested in leveraging stochastic analysis to improve diffusion models and large language model training.

Before joining Stanford, I obtained my Bachelor of Mathematics from Fudan University. I have conducted research under the supervision of Prof. Yinyu Ye and Prof. Ge. Additionally, I gained industrial research experience as an intern at ByteDance Seed and Shanghai AI Laboratory, working on diffusion model acceleration and domain-specific LLM adaptation.

My ultimate goal is to uncover the mysteries of intelligence and develop methods that enhance learning and improve lives. If you share similar interests, feel free to contact me via email.
